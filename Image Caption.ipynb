{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train/make the model, the dataset must be prepared. Since the downloading the dataset will take forever for each person to run each time, the resulting file will be available so that it can be accessed locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we'll be using the 2014 training dataset. To avoid overfitting the data onto the model, a smaller random sample will be used for training.\n",
    "This dataset comes with images and their respective captions, but these will be separated so that the model can be tested for accuracy.\n",
    "*One thing to note is that downloading the dataset will take up to a few hours, so don't run the cell below if you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
      "13510574080/13510573713 [==============================] - 12414s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Download training captions\n",
    "annotation_folder = '/annotations/'\n",
    "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
    "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
    "                                          cache_subdir=os.path.abspath('.'),\n",
    "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
    "                                          extract = True)\n",
    "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
    "  os.remove(annotation_zip)\n",
    "\n",
    "# Download training images\n",
    "image_folder = '/train2014/'\n",
    "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
    "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
    "                                      cache_subdir=os.path.abspath('.'),\n",
    "                                      origin = 'http://images.cocodataset.org/zips/train2014.zip',\n",
    "                                      extract = True)\n",
    "  PATH = os.path.dirname(image_zip) + image_folder\n",
    "  os.remove(image_zip)\n",
    "else:\n",
    "  PATH = os.path.abspath('.') + image_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file so the captions can be extracted (as well as associated images)\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "all_captions = []\n",
    "all_img_names = []\n",
    "\n",
    "for annot in annotations['annotations']:\n",
    "    caption = '<start> ' + annot['caption'] + ' <end>'\n",
    "    image_id = annot['image_id']\n",
    "    full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n",
    "    \n",
    "    all_img_names.append(full_coco_image_path)\n",
    "    all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multiple reduced sets to figure out the runtime for the smallest set, and eventually work up to the largest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total captions: 414113\n",
      "Number of 1% of captions: 4141\n",
      "Number of 5% of captions: 20706\n",
      "Number of 10% of captions: 41411\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total captions:\", len(all_captions))\n",
    "print(\"Number of 1% of captions:\", round(len(all_captions)*.01))\n",
    "print(\"Number of 5% of captions:\", round(len(all_captions)*.05))\n",
    "print(\"Number of 10% of captions:\", round(len(all_captions)*.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample the data accordingly, shuffling after resampling so that they don't have the same captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the order of the captions and the image names\n",
    "# Each respective caption should stay linked with its image\n",
    "train_captions_01 = []\n",
    "img_name_01 = []\n",
    "train_captions, img_name = shuffle(all_captions, all_img_names, random_state = 1)\n",
    "train_captions_01 = train_captions[:4141]\n",
    "img_name_01 = img_name[:4141]\n",
    "\n",
    "train_captions_05 = []\n",
    "img_name_05 = []\n",
    "train_captions, img_name = shuffle(all_captions, all_img_names, random_state = 1)\n",
    "train_captions_05 = train_captions[:20706]\n",
    "img_name_05 = img_name[:20706]\n",
    "\n",
    "train_captions_1 = []\n",
    "img_name_1 = []\n",
    "train_captions, img_name = shuffle(all_captions, all_img_names, random_state = 1)\n",
    "train_captions_1 = train_captions[:41411]\n",
    "img_name_1 = img_name[:41411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
